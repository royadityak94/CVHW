{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import utils\n",
    "from extractDigitFeatures import extractDigitFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.loadmat('../data/digits-normal.mat') \n",
    "features = extractDigitFeatures(data['x'], 'hog')\n",
    "#model = trainModel(features[:, data['set']==trainSet], data['y'][data['set']==trainSet])\n",
    "trainSet, testSet = 1, 2\n",
    "param = {}\n",
    "param['lambda'], param['maxiter'], param['eta'] = 0.01, 200,  .01\n",
    "# trainModel : x = features[data['set']==trainSet, :], y = data['y'][data['set']==trainSet]\n",
    "x_train = features[:, data['set']==trainSet]\n",
    "y_train = data['y'][data['set']==trainSet]\n",
    "\n",
    "x_val = features[:, data['set']==3]\n",
    "y_val = data['y'][data['set']==3]\n",
    "\n",
    "x_test = features[:, data['set']==testSet]\n",
    "y_test = data['y'][data['set']==testSet]\n",
    "\n",
    "# multiclassLRTrain : x, y, param\n",
    "classLabels = np.unique(y_train)\n",
    "numClass = classLabels.shape[0]\n",
    "numFeats = x_train.shape[0]\n",
    "numData = x_train.shape[1]\n",
    "\n",
    "# Initialize weights randomly (Implement gradient descent)\n",
    "#model = {}\n",
    "#model['w'] = np.random.randn(numClass, numFeats)*0.01\n",
    "#model['classLabels'] = classLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    def __init__(self, eta, lambda_, maxEpochs, numClass, debug=False, maxTol=10):\n",
    "        self.lr = eta\n",
    "        self.lambda_ = lambda_\n",
    "        self.max_epochs = maxEpochs\n",
    "        self.debug = debug\n",
    "        self.numClass = numClass\n",
    "        self.bias = np.random.uniform(low=-0.01, high=.01)\n",
    "        self.maxTol = maxTol\n",
    "        self.lastAccuracy = -1\n",
    "        \n",
    "    def softmax(self, X):\n",
    "        exp = np.exp(X - np.max(X))\n",
    "        return exp / np.array([np.sum(exp, axis=1)]).T\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        y_pred = np.argmax(self.softmax(np.dot(X.T, self.weights)+self.bias), axis=1)\n",
    "        self.y_pred = y_pred\n",
    "        return np.sum([y_pred[i] == y[i] for i in range(y.size)]) / y.size\n",
    "        \n",
    "    def fit(self, X, y, X_val, y_val):\n",
    "        self.weights = np.random.uniform(low=-0.01, high=.01, size=(X.shape[0], numClass))\n",
    "        y_categorical = np.eye(self.numClass)[y] \n",
    "        curTol = 0\n",
    "        \n",
    "        for itr in range(self.max_epochs):\n",
    "            prediction = self.softmax(np.dot(X.T, self.weights))\n",
    "            error = y_categorical - prediction\n",
    "            gradient = np.dot(X, error)\n",
    "            self.weights += self.lr * (gradient - (self.lambda_ * self.weights ))\n",
    "            self.bias -= self.lr * np.sum(error)\n",
    "            \n",
    "            \n",
    "            curr_accuracy = self.accuracy(X_val, y_val)\n",
    "            if curr_accuracy != self.lastAccuracy:\n",
    "                self.lastAccuracy = curr_accuracy\n",
    "            else:\n",
    "                curTol += 1\n",
    "                if curTol >= self.maxTol:\n",
    "                    return self\n",
    "            if itr % 50 == 0 and self.debug: \n",
    "                print (\"Accuracy = {}\".format(curr_accuracy))        \n",
    "        return self\n",
    "    \n",
    "    def confusion_matrix(self, y):\n",
    "        confusion_matrix = np.zeros((self.numClass, self.numClass))\n",
    "        for itr in range(self.y_pred.size):\n",
    "            confusion_matrix[y_test[itr], self.y_pred[itr]] += 1\n",
    "        return confusion_matrix\n",
    "    \n",
    "    def predict(self, X, y):\n",
    "        accuracy = self.accuracy(X, y)\n",
    "        confusion_matrix = self.confusion_matrix(y)\n",
    "        return accuracy, confusion_matrix\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(param['eta'], param['lambda'], param['maxiter'], numClass)\n",
    "model = model.fit(x_train, y_train, x_val, y_val)\n",
    "accuracy, confusion_mat = model.predict(x_test, y_test)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f61d7862400>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(confusion_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs682",
   "language": "python",
   "name": "cs682"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
