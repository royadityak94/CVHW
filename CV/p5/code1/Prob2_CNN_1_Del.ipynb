{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "from utils import loadmat\n",
    "from extractDigitFeatures import extractDigitFeatures\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Conv3D, UpSampling2D, Flatten, MaxPool2D, AveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.python.keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.constraints import unit_norm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_data(data1, data2, low, high, max_samples=100):\n",
    "    N, H1, W1, C1 = data1.shape\n",
    "    #_, N1 = data2.shape\n",
    "    suff_data1 = np.zeros((max_samples, H1, W1, C1))\n",
    "    suff_data2 = np.zeros((max_samples,))\n",
    "    shuffles = np.random.randint(low, high+1, max_samples)\n",
    "    for idx in range(shuffles.shape[0]):\n",
    "        suff_data1[idx] = data1[idx, :, :, :]\n",
    "        suff_data2[idx] = data2[idx]\n",
    "    return suff_data1, suff_data2\n",
    "\n",
    "def reformat(x):\n",
    "    new_x = np.zeros((x.shape[2], x.shape[0], x.shape[1]))\n",
    "    for i in range(x.shape[2]):\n",
    "        new_x[i, :] = x[:, :, i]\n",
    "    return new_x[:, :, :, np.newaxis]\n",
    "\n",
    "def return_datasets(filename):\n",
    "    data = utils.loadmat('../data/{}'.format(filename))\n",
    "    trainSet, testSet, valSet = 1, 2, 3\n",
    "    \n",
    "    x_train = reformat(data['x'][:, :, data['set']==trainSet ])\n",
    "    y_train = (data['y'][data['set']==trainSet])\n",
    "    x_val = reformat(data['x'][:, :, data['set']==valSet])\n",
    "    y_val = (data['y'][data['set']==valSet])\n",
    "    x_test = reformat(data['x'][:, :, data['set']==testSet])\n",
    "    y_test = (data['y'][data['set']==testSet])\n",
    "    \n",
    "    x_train, y_train = get_random_data(x_train, y_train, 0, x_train.shape[0], x_train.shape[0])\n",
    "    x_val, y_val = get_random_data(x_val, y_val, 0, x_val.shape[0], x_val.shape[0])\n",
    "    x_test, y_test = get_random_data(x_test, y_test, 0, x_test.shape[0], x_test.shape[0])\n",
    "    \n",
    "    #print (x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape)\n",
    "    \n",
    "\n",
    "    #return (X, Y, x_test, y_test)\n",
    "    return (x_train, y_train, x_val, y_val, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model(activation_func = 'relu'):\n",
    "    model = Sequential()\n",
    "    kernel_size=(5)\n",
    "    stride_size = (2)\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=kernel_size, strides=stride_size, activation=activation_func, padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPool2D(2, 2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, kernel_size=kernel_size, strides=stride_size, activation=activation_func, padding='same'))\n",
    "    model.add(MaxPool2D(2, 2))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "#     model.add(Conv2D(64, kernel_size=kernel_size, strides=stride_size, activation=activation_func, padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=kernel_size, strides=stride_size, activation=activation_func, padding='same'))\n",
    "    model.add(MaxPool2D(2, 2))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(96, kernel_size=kernel_size, strides=stride_size, activation=activation_func, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=activation_func)) \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 30\n",
    "MAX_BATCH_SIZE = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 35s 35ms/sample - loss: 1.0754 - accuracy: 0.6800\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 0s 366us/sample - loss: 0.3140 - accuracy: 0.9200\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 0s 390us/sample - loss: 0.1400 - accuracy: 0.9670\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 0s 386us/sample - loss: 0.0832 - accuracy: 0.9810\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 0s 382us/sample - loss: 0.0760 - accuracy: 0.9790\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 0s 382us/sample - loss: 0.0633 - accuracy: 0.9820\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 0s 393us/sample - loss: 0.0985 - accuracy: 0.9690\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 0s 392us/sample - loss: 0.1034 - accuracy: 0.9670\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 0s 386us/sample - loss: 0.0551 - accuracy: 0.9860\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 0s 392us/sample - loss: 0.0358 - accuracy: 0.9890\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 0s 391us/sample - loss: 0.0322 - accuracy: 0.9890\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 0s 393us/sample - loss: 0.0249 - accuracy: 0.9920\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 0s 417us/sample - loss: 0.0103 - accuracy: 0.9980\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 0s 381us/sample - loss: 0.0110 - accuracy: 0.9970\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 0s 383us/sample - loss: 0.0127 - accuracy: 0.9940\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 0s 384us/sample - loss: 0.0208 - accuracy: 0.9930\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 0s 377us/sample - loss: 0.0458 - accuracy: 0.9900\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 0s 370us/sample - loss: 0.0154 - accuracy: 0.9950\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 0s 366us/sample - loss: 0.0164 - accuracy: 0.9980\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 0s 377us/sample - loss: 0.0412 - accuracy: 0.9870\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 0s 377us/sample - loss: 0.0352 - accuracy: 0.9880\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 0s 362us/sample - loss: 0.0654 - accuracy: 0.9800\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 0s 375us/sample - loss: 0.0673 - accuracy: 0.9780\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 0s 382us/sample - loss: 0.0556 - accuracy: 0.9800\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 0s 385us/sample - loss: 0.0360 - accuracy: 0.9890\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 0s 378us/sample - loss: 0.0644 - accuracy: 0.9770\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 0s 378us/sample - loss: 0.0412 - accuracy: 0.9910\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 0s 370us/sample - loss: 0.0370 - accuracy: 0.9900\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 0s 371us/sample - loss: 0.0209 - accuracy: 0.9930\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 0s 379us/sample - loss: 0.0035 - accuracy: 0.9990\n",
      "0.92\n"
     ]
    }
   ],
   "source": [
    "file = 'digits-normal.mat'\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = return_datasets(file)\n",
    "\n",
    "model = extract_model('relu')\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='Adam', validation_data=(x_val, to_categorical(y_val, num_classes=10)), metrics=[\"accuracy\"])\n",
    "model.fit(x_train, to_categorical(y_train, num_classes=10), epochs=MAX_EPOCHS, batch_size=MAX_BATCH_SIZE, verbose=1)\n",
    "accuracy = model.evaluate(x_test, to_categorical(y_test, num_classes=10), verbose=0)[1]\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 1.6925 - accuracy: 0.4300\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.9311 - accuracy: 0.7010\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.7029 - accuracy: 0.7730\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6725 - accuracy: 0.7930\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5581 - accuracy: 0.8100\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5000 - accuracy: 0.8420\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4271 - accuracy: 0.8620\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3118 - accuracy: 0.9040\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3431 - accuracy: 0.8880\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3009 - accuracy: 0.8960\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3599 - accuracy: 0.8900\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2997 - accuracy: 0.9100\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2621 - accuracy: 0.9260\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2575 - accuracy: 0.9260\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 9s 9ms/sample - loss: 0.2709 - accuracy: 0.9160\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 257s 257ms/sample - loss: 0.2889 - accuracy: 0.9200\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 16s 16ms/sample - loss: 0.2348 - accuracy: 0.9260\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 1s 580us/sample - loss: 0.2046 - accuracy: 0.9330\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 1s 560us/sample - loss: 0.2408 - accuracy: 0.9290\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 1s 582us/sample - loss: 0.2353 - accuracy: 0.9240\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 1s 543us/sample - loss: 0.1819 - accuracy: 0.9500\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.1750 - accuracy: 0.9490\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.1959 - accuracy: 0.9410\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 1s 521us/sample - loss: 0.1632 - accuracy: 0.9500\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.1591 - accuracy: 0.9510\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 0.1642 - accuracy: 0.9500\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.1691 - accuracy: 0.9500\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 0.2094 - accuracy: 0.9400\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 1s 525us/sample - loss: 0.1619 - accuracy: 0.9500\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.1626 - accuracy: 0.9430\n"
     ]
    }
   ],
   "source": [
    "file = 'digits-scaled.mat'\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = return_datasets(file)\n",
    "\n",
    "model = extract_model('selu')\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='Adam', validation_data=(x_val, to_categorical(y_val, num_classes=10)), metrics=[\"accuracy\"])\n",
    "model.fit(x_train, to_categorical(y_train, num_classes=10), epochs=MAX_EPOCHS, batch_size=MAX_BATCH_SIZE, verbose=1)\n",
    "accuracy = model.evaluate(x_test, to_categorical(y_test, num_classes=10), verbose=0)[1]\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.836"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples\n",
      "Epoch 1/30\n",
      "900/900 [==============================] - 56s 62ms/sample - loss: 1.8467 - accuracy: 0.3867\n",
      "Epoch 2/30\n",
      "900/900 [==============================] - 1s 655us/sample - loss: 1.0552 - accuracy: 0.6522\n",
      "Epoch 3/30\n",
      "900/900 [==============================] - 0s 531us/sample - loss: 0.8165 - accuracy: 0.7489\n",
      "Epoch 4/30\n",
      "900/900 [==============================] - 0s 518us/sample - loss: 0.6959 - accuracy: 0.7722\n",
      "Epoch 5/30\n",
      "900/900 [==============================] - 0s 534us/sample - loss: 0.6550 - accuracy: 0.7922\n",
      "Epoch 6/30\n",
      "900/900 [==============================] - 1s 597us/sample - loss: 0.5903 - accuracy: 0.8133\n",
      "Epoch 7/30\n",
      "900/900 [==============================] - 0s 516us/sample - loss: 0.4454 - accuracy: 0.8700\n",
      "Epoch 8/30\n",
      "900/900 [==============================] - 0s 514us/sample - loss: 0.3975 - accuracy: 0.8767\n",
      "Epoch 9/30\n",
      "900/900 [==============================] - 0s 522us/sample - loss: 0.4030 - accuracy: 0.8789\n",
      "Epoch 10/30\n",
      "900/900 [==============================] - 1s 620us/sample - loss: 0.3654 - accuracy: 0.8778\n",
      "Epoch 11/30\n",
      "900/900 [==============================] - 0s 526us/sample - loss: 0.3460 - accuracy: 0.8922\n",
      "Epoch 12/30\n",
      "900/900 [==============================] - 0s 522us/sample - loss: 0.3533 - accuracy: 0.8956\n",
      "Epoch 13/30\n",
      "900/900 [==============================] - 0s 538us/sample - loss: 0.3461 - accuracy: 0.8989\n",
      "Epoch 14/30\n",
      "900/900 [==============================] - 0s 510us/sample - loss: 0.3562 - accuracy: 0.8978\n",
      "Epoch 15/30\n",
      "900/900 [==============================] - 0s 524us/sample - loss: 0.2962 - accuracy: 0.9167\n",
      "Epoch 16/30\n",
      "900/900 [==============================] - 1s 611us/sample - loss: 0.2369 - accuracy: 0.9311\n",
      "Epoch 17/30\n",
      "900/900 [==============================] - 1s 619us/sample - loss: 0.2847 - accuracy: 0.9122\n",
      "Epoch 18/30\n",
      "900/900 [==============================] - 0s 533us/sample - loss: 0.2342 - accuracy: 0.9278\n",
      "Epoch 19/30\n",
      "900/900 [==============================] - 0s 525us/sample - loss: 0.2441 - accuracy: 0.9178\n",
      "Epoch 20/30\n",
      "900/900 [==============================] - 1s 616us/sample - loss: 0.2208 - accuracy: 0.9311\n",
      "Epoch 21/30\n",
      "900/900 [==============================] - 1s 556us/sample - loss: 0.2049 - accuracy: 0.9378\n",
      "Epoch 22/30\n",
      "900/900 [==============================] - 0s 514us/sample - loss: 0.2572 - accuracy: 0.9233\n",
      "Epoch 23/30\n",
      "900/900 [==============================] - 0s 522us/sample - loss: 0.1761 - accuracy: 0.9456\n",
      "Epoch 24/30\n",
      "900/900 [==============================] - 0s 525us/sample - loss: 0.2013 - accuracy: 0.9467\n",
      "Epoch 25/30\n",
      "900/900 [==============================] - 0s 520us/sample - loss: 0.1689 - accuracy: 0.9356\n",
      "Epoch 26/30\n",
      "900/900 [==============================] - 0s 523us/sample - loss: 0.2056 - accuracy: 0.9389\n",
      "Epoch 27/30\n",
      "900/900 [==============================] - 0s 516us/sample - loss: 0.2417 - accuracy: 0.9322\n",
      "Epoch 28/30\n",
      "900/900 [==============================] - 0s 530us/sample - loss: 0.2071 - accuracy: 0.9289\n",
      "Epoch 29/30\n",
      "900/900 [==============================] - 0s 507us/sample - loss: 0.2162 - accuracy: 0.9400\n",
      "Epoch 30/30\n",
      "900/900 [==============================] - 0s 524us/sample - loss: 0.1486 - accuracy: 0.9567\n",
      "Accuracy = 0.8220000267028809\n",
      "Train on 900 samples\n",
      "Epoch 1/30\n",
      "900/900 [==============================] - 2s 2ms/sample - loss: 1.7365 - accuracy: 0.4078\n",
      "Epoch 2/30\n",
      "900/900 [==============================] - 1s 566us/sample - loss: 1.0081 - accuracy: 0.6800\n",
      "Epoch 3/30\n",
      "900/900 [==============================] - 1s 567us/sample - loss: 0.8012 - accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "900/900 [==============================] - 1s 580us/sample - loss: 0.6104 - accuracy: 0.8044\n",
      "Epoch 5/30\n",
      "900/900 [==============================] - 1s 577us/sample - loss: 0.4886 - accuracy: 0.8522\n",
      "Epoch 6/30\n",
      "900/900 [==============================] - 1s 577us/sample - loss: 0.4652 - accuracy: 0.8489\n",
      "Epoch 7/30\n",
      "900/900 [==============================] - 1s 578us/sample - loss: 0.4534 - accuracy: 0.8578\n",
      "Epoch 8/30\n",
      "900/900 [==============================] - 1s 575us/sample - loss: 0.3919 - accuracy: 0.8767\n",
      "Epoch 9/30\n",
      "900/900 [==============================] - 1s 579us/sample - loss: 0.3740 - accuracy: 0.8800\n",
      "Epoch 10/30\n",
      "900/900 [==============================] - 1s 583us/sample - loss: 0.3714 - accuracy: 0.8844\n",
      "Epoch 11/30\n",
      "900/900 [==============================] - 1s 573us/sample - loss: 0.3313 - accuracy: 0.8944\n",
      "Epoch 12/30\n",
      "900/900 [==============================] - 1s 580us/sample - loss: 0.3387 - accuracy: 0.8989\n",
      "Epoch 13/30\n",
      "900/900 [==============================] - 1s 570us/sample - loss: 0.2960 - accuracy: 0.9044\n",
      "Epoch 14/30\n",
      "900/900 [==============================] - 3s 3ms/sample - loss: 0.2629 - accuracy: 0.9100\n",
      "Epoch 15/30\n",
      "900/900 [==============================] - 187s 208ms/sample - loss: 0.2345 - accuracy: 0.9300\n",
      "Epoch 16/30\n",
      "200/900 [=====>........................] - ETA: 4:50 - loss: 0.2103 - accuracy: 0.9314"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-62d2fe999eda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_x_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_y_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_BATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs682/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/cs682/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs682/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs682/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs682/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs682/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs682/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs682/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs682/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs682/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/cs682/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file = 'digits-scaled.mat'\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = return_datasets(file)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "best_model, best_accuracy = -1, -1\n",
    "\n",
    "for train, test in kfold.split(x_train, y_train):\n",
    "    curr_x_train, curr_y_train = x_train[train], to_categorical(y_train[train], num_classes=10)\n",
    "    curr_x_val, curr_y_val = x_train[train], to_categorical(y_train[train], num_classes=10)\n",
    "    \n",
    "    model = extract_model()\n",
    "    if file == 'digits-scaled.mat':\n",
    "        model = extract_model('selu')\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='Adam', validation_data=(curr_x_val, curr_y_val), metrics=[\"accuracy\"])\n",
    "    model.fit(curr_x_train, curr_y_train, epochs=MAX_EPOCHS, batch_size=MAX_BATCH_SIZE, verbose=1)\n",
    "    accuracy = model.evaluate(x_val, to_categorical(y_val, num_classes=10), verbose=0)[1]\n",
    "    print (\"Accuracy = {}\".format(accuracy))\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy, best_model = accuracy, model\n",
    "\n",
    "print (\"Test Set Accuracy for {} = {}\".format(file, best_model.evaluate(x_test, to_categorical(y_test, num_classes=10), verbose=0)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs682",
   "language": "python",
   "name": "cs682"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
