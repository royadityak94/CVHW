{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "from utils import loadmat\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, UpSampling2D, Flatten, MaxPool2D, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_data(data1, data2, low, high, max_samples=100):\n",
    "    N, H1, W1, C1 = data1.shape\n",
    "    suff_data1 = np.zeros((max_samples, H1, W1, C1))\n",
    "    suff_data2 = np.zeros((max_samples,))\n",
    "    shuffles = np.random.randint(low, high+1, max_samples)\n",
    "    for idx in range(shuffles.shape[0]):\n",
    "        suff_data1[idx] = data1[idx, :, :, :]\n",
    "        suff_data2[idx] = data2[idx]\n",
    "    return suff_data1, suff_data2\n",
    "\n",
    "def reformat(x):\n",
    "    new_x = np.zeros((x.shape[2], x.shape[0], x.shape[1]))\n",
    "    for i in range(x.shape[2]):\n",
    "        new_x[i, :] = x[:, :, i]\n",
    "    return new_x[:, :, :, np.newaxis]\n",
    "\n",
    "def return_datasets(filename):\n",
    "    data = utils.loadmat('../data/{}'.format(filename))\n",
    "    trainSet, testSet, valSet = 1, 2, 3\n",
    "    \n",
    "    x_train = reformat(data['x'][:, :, data['set']==trainSet ])\n",
    "    y_train = (data['y'][data['set']==trainSet])\n",
    "    x_val = reformat(data['x'][:, :, data['set']==valSet])\n",
    "    y_val = (data['y'][data['set']==valSet])\n",
    "    x_test = reformat(data['x'][:, :, data['set']==testSet])\n",
    "    y_test = (data['y'][data['set']==testSet])\n",
    "    \n",
    "    x_train, y_train = get_random_data(x_train, y_train, 0, x_train.shape[0], x_train.shape[0])\n",
    "    x_val, y_val = get_random_data(x_val, y_val, 0, x_val.shape[0], x_val.shape[0])\n",
    "    x_test, y_test = get_random_data(x_test, y_test, 0, x_test.shape[0], x_test.shape[0])\n",
    "    \n",
    "    return (x_train, y_train, x_val, y_val, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model(activation_func = 'relu'):\n",
    "    model = Sequential()\n",
    "    kernel_size=(5)\n",
    "    stride_size = (2)\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=kernel_size, strides=stride_size, activation=activation_func, padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPool2D(2, 2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, kernel_size=kernel_size, strides=stride_size, activation=activation_func, padding='same'))\n",
    "    model.add(MaxPool2D(2, 2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=kernel_size, strides=stride_size, activation=activation_func, padding='same'))\n",
    "    model.add(MaxPool2D(2, 2))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "    model.add(Conv2D(96, kernel_size=kernel_size, strides=stride_size, activation=activation_func, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=activation_func)) \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/25\n",
      "1000/1000 [==============================] - 6s 6ms/sample - loss: 2.1042 - accuracy: 0.2580\n",
      "Epoch 2/25\n",
      "1000/1000 [==============================] - 1s 826us/sample - loss: 1.5233 - accuracy: 0.4550\n",
      "Epoch 3/25\n",
      "1000/1000 [==============================] - 1s 836us/sample - loss: 1.0931 - accuracy: 0.6450\n",
      "Epoch 4/25\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.7892 - accuracy: 0.7320\n",
      "Epoch 5/25\n",
      "1000/1000 [==============================] - 6s 6ms/sample - loss: 0.6110 - accuracy: 0.7890\n",
      "Epoch 6/25\n",
      "1000/1000 [==============================] - 168s 168ms/sample - loss: 0.4657 - accuracy: 0.8300\n",
      "Epoch 7/25\n",
      "1000/1000 [==============================] - 89s 89ms/sample - loss: 0.3394 - accuracy: 0.8870\n",
      "Epoch 8/25\n",
      "1000/1000 [==============================] - 1s 870us/sample - loss: 0.2691 - accuracy: 0.9070\n",
      "Epoch 9/25\n",
      "1000/1000 [==============================] - 1s 875us/sample - loss: 0.2243 - accuracy: 0.9220\n",
      "Epoch 10/25\n",
      "1000/1000 [==============================] - 1s 866us/sample - loss: 0.2949 - accuracy: 0.9080\n",
      "Epoch 11/25\n",
      "1000/1000 [==============================] - 1s 845us/sample - loss: 0.2543 - accuracy: 0.9190\n",
      "Epoch 12/25\n",
      "1000/1000 [==============================] - 1s 882us/sample - loss: 0.2335 - accuracy: 0.9140\n",
      "Epoch 13/25\n",
      "1000/1000 [==============================] - 1s 823us/sample - loss: 0.1611 - accuracy: 0.9410\n",
      "Epoch 14/25\n",
      "1000/1000 [==============================] - 1s 933us/sample - loss: 0.1862 - accuracy: 0.9420\n",
      "Epoch 15/25\n",
      "1000/1000 [==============================] - 1s 791us/sample - loss: 0.1799 - accuracy: 0.9420\n",
      "Epoch 16/25\n",
      "1000/1000 [==============================] - 1s 736us/sample - loss: 0.2304 - accuracy: 0.9200\n",
      "Epoch 17/25\n",
      "1000/1000 [==============================] - 1s 760us/sample - loss: 0.2184 - accuracy: 0.9220\n",
      "Epoch 18/25\n",
      "1000/1000 [==============================] - 1s 725us/sample - loss: 0.1813 - accuracy: 0.9340\n",
      "Epoch 19/25\n",
      "1000/1000 [==============================] - 1s 726us/sample - loss: 0.1444 - accuracy: 0.9540\n",
      "Epoch 20/25\n",
      "1000/1000 [==============================] - 1s 785us/sample - loss: 0.1526 - accuracy: 0.9460\n",
      "Epoch 21/25\n",
      "1000/1000 [==============================] - 1s 784us/sample - loss: 0.1274 - accuracy: 0.9550\n",
      "Epoch 22/25\n",
      "1000/1000 [==============================] - 1s 778us/sample - loss: 0.0944 - accuracy: 0.9670\n",
      "Epoch 23/25\n",
      "1000/1000 [==============================] - 1s 819us/sample - loss: 0.1622 - accuracy: 0.9470\n",
      "Epoch 24/25\n",
      "1000/1000 [==============================] - 1s 742us/sample - loss: 0.1773 - accuracy: 0.9490\n",
      "Epoch 25/25\n",
      "1000/1000 [==============================] - 1s 782us/sample - loss: 0.0876 - accuracy: 0.9750\n",
      "Accuracy = 0.7400000095367432\n",
      "Train on 1000 samples\n",
      "Epoch 1/25\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 1.0597 - accuracy: 0.6690\n",
      "Epoch 2/25\n",
      "1000/1000 [==============================] - 1s 879us/sample - loss: 0.4348 - accuracy: 0.8600\n",
      "Epoch 3/25\n",
      "1000/1000 [==============================] - 1s 889us/sample - loss: 0.2818 - accuracy: 0.9140\n",
      "Epoch 4/25\n",
      "1000/1000 [==============================] - 1s 929us/sample - loss: 0.2931 - accuracy: 0.9040\n",
      "Epoch 5/25\n",
      "1000/1000 [==============================] - 1s 859us/sample - loss: 0.2238 - accuracy: 0.9270\n",
      "Epoch 6/25\n",
      "1000/1000 [==============================] - 1s 848us/sample - loss: 0.1227 - accuracy: 0.9620\n",
      "Epoch 7/25\n",
      "1000/1000 [==============================] - 1s 844us/sample - loss: 0.1844 - accuracy: 0.9430\n",
      "Epoch 8/25\n",
      "1000/1000 [==============================] - 1s 869us/sample - loss: 0.1322 - accuracy: 0.9600\n",
      "Epoch 9/25\n",
      "1000/1000 [==============================] - 4s 4ms/sample - loss: 0.1234 - accuracy: 0.9610\n",
      "Epoch 10/25\n",
      "1000/1000 [==============================] - 272s 272ms/sample - loss: 0.1253 - accuracy: 0.9640\n",
      "Epoch 11/25\n",
      "1000/1000 [==============================] - 1s 829us/sample - loss: 0.0860 - accuracy: 0.9680\n",
      "Epoch 12/25\n",
      "1000/1000 [==============================] - 1s 884us/sample - loss: 0.1081 - accuracy: 0.9690\n",
      "Epoch 13/25\n",
      "1000/1000 [==============================] - 1s 815us/sample - loss: 0.0718 - accuracy: 0.9810\n",
      "Epoch 14/25\n",
      "1000/1000 [==============================] - 1s 883us/sample - loss: 0.0534 - accuracy: 0.9870\n",
      "Epoch 15/25\n",
      "1000/1000 [==============================] - 1s 759us/sample - loss: 0.0562 - accuracy: 0.9830\n",
      "Epoch 16/25\n",
      "1000/1000 [==============================] - 1s 804us/sample - loss: 0.1594 - accuracy: 0.9470\n",
      "Epoch 17/25\n",
      "1000/1000 [==============================] - 1s 834us/sample - loss: 0.0862 - accuracy: 0.9710\n",
      "Epoch 18/25\n",
      "1000/1000 [==============================] - 1s 843us/sample - loss: 0.0480 - accuracy: 0.9810\n",
      "Epoch 19/25\n",
      "1000/1000 [==============================] - 1s 840us/sample - loss: 0.0763 - accuracy: 0.9750\n",
      "Epoch 20/25\n",
      "1000/1000 [==============================] - 1s 845us/sample - loss: 0.0531 - accuracy: 0.9810\n",
      "Epoch 21/25\n",
      "1000/1000 [==============================] - 1s 844us/sample - loss: 0.0589 - accuracy: 0.9790\n",
      "Epoch 22/25\n",
      "1000/1000 [==============================] - 1s 840us/sample - loss: 0.0518 - accuracy: 0.9840\n",
      "Epoch 23/25\n",
      "1000/1000 [==============================] - 1s 845us/sample - loss: 0.0559 - accuracy: 0.9850\n",
      "Epoch 24/25\n",
      "1000/1000 [==============================] - 1s 886us/sample - loss: 0.0933 - accuracy: 0.9740\n",
      "Epoch 25/25\n",
      "1000/1000 [==============================] - 1s 764us/sample - loss: 0.0743 - accuracy: 0.9720\n",
      "Accuracy = 0.9020000100135803\n",
      "Train on 1000 samples\n",
      "Epoch 1/25\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 1.9384 - accuracy: 0.3520\n",
      "Epoch 2/25\n",
      "1000/1000 [==============================] - 1s 960us/sample - loss: 1.2417 - accuracy: 0.5920\n",
      "Epoch 3/25\n",
      "1000/1000 [==============================] - 1s 957us/sample - loss: 0.9783 - accuracy: 0.6950\n",
      "Epoch 4/25\n",
      "1000/1000 [==============================] - 1s 969us/sample - loss: 0.8358 - accuracy: 0.7410\n",
      "Epoch 5/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6660 - accuracy: 0.7910\n",
      "Epoch 6/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5578 - accuracy: 0.8270\n",
      "Epoch 7/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5602 - accuracy: 0.8200\n",
      "Epoch 8/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4738 - accuracy: 0.8560\n",
      "Epoch 9/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4687 - accuracy: 0.8550\n",
      "Epoch 10/25\n",
      "1000/1000 [==============================] - 275s 275ms/sample - loss: 0.3802 - accuracy: 0.8760\n",
      "Epoch 11/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3674 - accuracy: 0.8780\n",
      "Epoch 12/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3248 - accuracy: 0.8910\n",
      "Epoch 13/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3201 - accuracy: 0.9010\n",
      "Epoch 14/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3343 - accuracy: 0.8950\n",
      "Epoch 15/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3383 - accuracy: 0.8840\n",
      "Epoch 16/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2589 - accuracy: 0.9110\n",
      "Epoch 17/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2458 - accuracy: 0.9190\n",
      "Epoch 18/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3192 - accuracy: 0.9080\n",
      "Epoch 19/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2537 - accuracy: 0.9230\n",
      "Epoch 20/25\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 0.2222 - accuracy: 0.9320\n",
      "Epoch 21/25\n",
      "1000/1000 [==============================] - 4s 4ms/sample - loss: 0.2240 - accuracy: 0.9280\n",
      "Epoch 22/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2160 - accuracy: 0.9340\n",
      "Epoch 23/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2335 - accuracy: 0.9240\n",
      "Epoch 24/25\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2307 - accuracy: 0.9290\n",
      "Epoch 25/25\n",
      "1000/1000 [==============================] - 58s 58ms/sample - loss: 0.2086 - accuracy: 0.9400\n",
      "Accuracy = 0.8399999737739563\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 10\n",
    "MAX_EPOCHS, MAX_BATCH_SIZE = 25, 25\n",
    "files = ['digits-jitter.mat', 'digits-normal.mat', 'digits-scaled.mat'] \n",
    "for file in files:\n",
    "    model = extract_model('relu')\n",
    "    \n",
    "    if file == 'digits-jitter.mat':\n",
    "        MAX_EPOCHS, MAX_BATCH_SIZE = 25, 10\n",
    "    elif file == 'digits-scaled.mat':\n",
    "        model = extract_model('selu')\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = return_datasets(file)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='Adam', validation_data=(x_val, to_categorical(y_val, num_classes=NUM_CLASSES)), metrics=[\"accuracy\"])\n",
    "    model.fit(x_train, to_categorical(y_train, num_classes=NUM_CLASSES), epochs=MAX_EPOCHS, batch_size=MAX_BATCH_SIZE, verbose=1)\n",
    "    accuracy = model.evaluate(x_test, to_categorical(y_test, num_classes=10), verbose=0)[1]\n",
    "    print (\"Accuracy = {}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs682",
   "language": "python",
   "name": "cs682"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
