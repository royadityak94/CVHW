{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "from utils import loadmat\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, UpSampling2D, Flatten, MaxPool2D, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_data(data1, data2, low, high, max_samples=100):\n",
    "    N, H1, W1, C1 = data1.shape\n",
    "    suff_data1 = np.zeros((max_samples, H1, W1, C1))\n",
    "    suff_data2 = np.zeros((max_samples,))\n",
    "    shuffles = np.random.randint(low, high+1, max_samples)\n",
    "    for idx in range(shuffles.shape[0]):\n",
    "        suff_data1[idx] = data1[idx, :, :, :]\n",
    "        suff_data2[idx] = data2[idx]\n",
    "    return suff_data1, suff_data2\n",
    "\n",
    "def reformat(x):\n",
    "    new_x = np.zeros((x.shape[2], x.shape[0], x.shape[1]))\n",
    "    for i in range(x.shape[2]):\n",
    "        new_x[i, :] = x[:, :, i]\n",
    "    return new_x[:, :, :, np.newaxis]\n",
    "\n",
    "def return_datasets(filename):\n",
    "    data = utils.loadmat('../data/{}'.format(filename))\n",
    "    trainSet, testSet, valSet = 1, 2, 3\n",
    "    \n",
    "    x_train = reformat(data['x'][:, :, data['set']==trainSet ])\n",
    "    y_train = (data['y'][data['set']==trainSet])\n",
    "    x_val = reformat(data['x'][:, :, data['set']==valSet])\n",
    "    y_val = (data['y'][data['set']==valSet])\n",
    "    x_test = reformat(data['x'][:, :, data['set']==testSet])\n",
    "    y_test = (data['y'][data['set']==testSet])\n",
    "    \n",
    "    x_train, y_train = get_random_data(x_train, y_train, 0, x_train.shape[0], x_train.shape[0])\n",
    "    x_val, y_val = get_random_data(x_val, y_val, 0, x_val.shape[0], x_val.shape[0])\n",
    "    x_test, y_test = get_random_data(x_test, y_test, 0, x_test.shape[0], x_test.shape[0])\n",
    "    \n",
    "    return (x_train, y_train, x_val, y_val, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model(activation_func = 'relu'):\n",
    "    model = Sequential()\n",
    "    kernel_size=(5)\n",
    "    stride_size = (2)\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=kernel_size, strides=stride_size, activation=activation_func, padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPool2D(2, 2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, kernel_size=kernel_size, strides=stride_size, activation=activation_func, padding='same'))\n",
    "    model.add(MaxPool2D(2, 2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=kernel_size, strides=stride_size, activation=activation_func, padding='same'))\n",
    "    model.add(MaxPool2D(2, 2))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "    model.add(Conv2D(96, kernel_size=kernel_size, strides=stride_size, activation=activation_func, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=activation_func)) \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7020000219345093\n",
      "Accuracy = 0.9179999828338623\n",
      "Accuracy = 0.828000009059906\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 10\n",
    "MAX_EPOCHS, MAX_BATCH_SIZE = 25, 25\n",
    "files = ['digits-jitter.mat', 'digits-normal.mat', 'digits-scaled.mat'] \n",
    "for file in files:\n",
    "    model = extract_model('relu')\n",
    "    \n",
    "    if file == 'digits-jitter.mat':\n",
    "        MAX_EPOCHS, MAX_BATCH_SIZE = 25, 10\n",
    "    elif file == 'digits-scaled.mat':\n",
    "        model = extract_model('selu')\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = return_datasets(file)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='Adam', validation_data=(x_val, to_categorical(y_val, num_classes=NUM_CLASSES)), metrics=[\"accuracy\"])\n",
    "    model.fit(x_train, to_categorical(y_train, num_classes=NUM_CLASSES), epochs=MAX_EPOCHS, batch_size=MAX_BATCH_SIZE, verbose=0)\n",
    "    accuracy = model.evaluate(x_test, to_categorical(y_test, num_classes=10), verbose=0)[1]\n",
    "    print (\"Accuracy = {}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs682",
   "language": "python",
   "name": "cs682"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
