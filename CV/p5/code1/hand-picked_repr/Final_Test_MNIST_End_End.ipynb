{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import utils\n",
    "import time\n",
    "#from extractDigitFeatures import extractDigitFeatures\n",
    "#from trainModel import trainModel\n",
    "from evaluateLabels import evaluateLabels\n",
    "from evaluateModel import evaluateModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are three versions of MNIST dataset\n",
    "dataTypes = ['digits-jitter.mat'] #'digits-normal.mat', 'digits-scaled.mat', \n",
    "\n",
    "# You have to implement three types of features\n",
    "featureTypes = ['pixel', 'hog', 'lbp'] # \n",
    "\n",
    "# Accuracy placeholder\n",
    "accuracy_mat = np.zeros((len(dataTypes), len(featureTypes)))\n",
    "val_accuracy = np.zeros((len(dataTypes), len(featureTypes)))\n",
    "trainSet = 1\n",
    "testSet = 2\n",
    "validationSet = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Loading digits of dataType: digits-jitter.mat\n",
      "2.79s to extract pixel features for 2000 images\n",
      "18.99s to train model\n",
      "Accuracy [validationSet=3] 0.14\n",
      "\n",
      "Accuracy [testSet=2] 15.80\n",
      "\n",
      "9.14s to extract hog features for 2000 images\n",
      "73.34s to train model\n",
      "Accuracy [validationSet=3] 0.10\n",
      "\n",
      "Accuracy [testSet=2] 10.00\n",
      "\n",
      "25.76s to extract lbp features for 2000 images\n",
      "3.06s to train model\n",
      "Accuracy [validationSet=3] 0.56\n",
      "\n",
      "Accuracy [testSet=2] 59.80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataTypes)):\n",
    "    dataType = dataTypes[i]\n",
    "    #Load data\n",
    "    path = os.path.join('../..', 'data', dataType)\n",
    "    data = utils.loadmat(path)\n",
    "    print ('+++ Loading digits of dataType: {}'.format(dataType))\n",
    "\n",
    "    # Optionally montage the digits in the val set\n",
    "    #montageDigits(data['x'][:, :, data['set']==2])\n",
    "\n",
    "    for j in range(len(featureTypes)):\n",
    "        featureType = featureTypes[j]\n",
    "\n",
    "        # Extract features\n",
    "        tic = time.time()\n",
    "        features = extractDigitFeatures(data['x'], featureType, dataType)\n",
    "        print ('{:.2f}s to extract {} features for {} images'.format(time.time()-tic,\n",
    "                featureType, features.shape[1]))\n",
    "\n",
    "        # Train model\n",
    "        tic = time.time()\n",
    "        model = trainModel(features[:, data['set']==trainSet], data['y'][data['set']==trainSet], \n",
    "                          features[:, data['set']==3], data['y'][data['set']==validationSet])\n",
    "        print ('{:.2f}s to train model'.format(time.time()-tic))\n",
    "        print ('Accuracy [validationSet={}] {:.2f}\\n'.format(validationSet, model['lastAccuracy']))\n",
    "\n",
    "        # Test the model\n",
    "        ypred = evaluateModel(model, features[:, data['set']==testSet])\n",
    "        y = data['y'][data['set']==testSet]\n",
    "\n",
    "        # Measure accuracy\n",
    "        (acc, conf) = evaluateLabels(y, ypred, False)\n",
    "        print ('Accuracy [testSet={}] {:.2f}\\n'.format(testSet, acc*100))\n",
    "        accuracy_mat[i, j] = acc\n",
    "        val_accuracy[i, j] = model['lastAccuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results in a table\n",
    "print ('+++ Accuracy Table [trainSet={}, validationSet = {}, testSet={}]'.format(trainSet, validationSet, testSet))\n",
    "print ('--------------------------------------------------')\n",
    "print ('dataset\\t\\t\\t',)\n",
    "for j in range(len(featureTypes)):\n",
    "    print ('{}\\t'.format(featureTypes[j]),)\n",
    "\n",
    "print ('')\n",
    "print ('--------------------------------------------------')\n",
    "for i in range(len(dataTypes)):\n",
    "    print ('{}\\t'.format(dataTypes[i]),)\n",
    "    for j in range(len(featureTypes)):\n",
    "        print ('{:.2f}\\t'.format(accuracy[i, j]*100), '{:.2f}\\t'.format(val_accuracy[i, j]*100))\n",
    "    print ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "from utils import loadmat\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "# EXTRACTDIGITFEATURES extracts features from digit images\n",
    "#   features = extractDigitFeatures(x, featureType) extracts FEATURES from images\n",
    "#   images X of the provided FEATURETYPE. The images are assumed to the of\n",
    "#   size [W H 1 N] where the first two dimensions are the width and height.\n",
    "#   The output is of size [D N] where D is the size of each feature and N\n",
    "#   is the number of images. \n",
    "\n",
    "def pixelFeatures(x):\n",
    "    return feature_normalization(x.reshape(-1), 'min-max')\n",
    "\n",
    "def feature_normalization(patch, type, epsilon=1e-5):\n",
    "    patch = patch.astype('longdouble')\n",
    "    if type == 'Sqrt':\n",
    "        return np.sqrt(patch)\n",
    "    elif type == 'L2-Norm':\n",
    "        return patch / np.sqrt(np.sum(patch ** 2) + epsilon)\n",
    "    elif type == 'min-max':\n",
    "        return (patch - patch.min()) / (patch.max() - patch.min())\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def extract_relevant_window(arr, patch_size, index_i, index_j):\n",
    "    curr_arr = np.zeros((patch_size, patch_size))\n",
    "    for i in range(patch_size):\n",
    "        for j in range(patch_size):\n",
    "            curr_arr[i][j] = arr[index_j*patch_size + i][index_i*patch_size + j]     \n",
    "    return curr_arr\n",
    "\n",
    "def hogFeatures(x):\n",
    "    # Applying Non Linear Mapping\n",
    "    img = feature_normalization (x, 'Sqrt')\n",
    "\n",
    "    # Computing the channel gradient\n",
    "    r_grad, c_grad = np.empty(img.shape).astype('longdouble'), np.empty(img.shape).astype('longdouble')\n",
    "    \n",
    "    r_grad[1:-1,] = img[2:, :] - img[:-2, :] \n",
    "    c_grad[:, 1:-1] = img[:, 2:] - img[:, :-2]\n",
    "    c_grad[:, 0], c_grad[:, -1] = 0, 0\n",
    "    r_grad[0, :], r_grad[-1, 0] = 0, 0\n",
    "\n",
    "    img_magnitude = np.sqrt(np.power(r_grad, 2) + np.power(c_grad, 2))\n",
    "    img_theta = np.rad2deg(np.arctan(c_grad/(r_grad+0.00000001))) % 180\n",
    "    orientation_bins = 8\n",
    "    patch_size = 4\n",
    "    tot_r, tot_c = img.shape\n",
    "    hog = np.zeros((int(tot_r/patch_size), int(tot_c/patch_size), orientation_bins))\n",
    "    for j in range(int(tot_c/patch_size)):\n",
    "        for i in range(int(tot_r/patch_size)):\n",
    "            # Extract the Current Patch and weight\n",
    "            curr_patch = extract_relevant_window(img_theta, patch_size, i, j)\n",
    "            curr_weight = extract_relevant_window(img_magnitude, patch_size, i, j)\n",
    "            # Applying Histogram calculations\n",
    "            hog[j][i] = np.histogram(np.ndarray.flatten(curr_patch), weights=np.ndarray.flatten(curr_weight), \n",
    "                                     bins=np.linspace(0, 180, num=(orientation_bins+1)))[0]        \n",
    "    hog_norm = feature_normalization(hog, 'min-max')\n",
    "    return hog_norm.ravel()\n",
    "\n",
    "def compute_from_patch(patch):\n",
    "    if patch.shape[0] != 3 and patch.shape[0] != patch.shape[1]:\n",
    "        raise ValueError('Patch Size Mismatch')\n",
    "    patch_sub = patch - np.ravel(patch)[4]\n",
    "    patch_sub[patch_sub>0] = 1\n",
    "    patch_sub[patch_sub<=0] = 0\n",
    "    flattened_patch = np.delete(np.ravel(patch_sub), 4)\n",
    "    return flattened_patch.dot(2**np.arange(flattened_patch.size)[::1])\n",
    "\n",
    "def lbpFeatures(x):\n",
    "    patch_size = 3\n",
    "    img = np.sqrt(x)\n",
    "    final_img = np.empty((img.shape[0]-(patch_size-1), img.shape[1]-(patch_size-1))).astype('longdouble')\n",
    "    for r in range(0, final_img.shape[0]):\n",
    "        for c in range(0, final_img.shape[1]):\n",
    "            final_img[r][c] = compute_from_patch(img[r:r+patch_size, c:c+patch_size])\n",
    "    return feature_normalization(np.histogram(np.ndarray.flatten(final_img), bins=np.linspace(1, 255, num=257))[0], 'min-max')\n",
    "\n",
    "def extractDigitFeatures(x, featureType, dataType):\n",
    "    N = x.shape[2]\n",
    "    \n",
    "    if featureType == 'pixel':\n",
    "        features = np.empty((784, N)).astype('longdouble')\n",
    "        features = np.array(Parallel(n_jobs=multiprocessing.cpu_count()) \n",
    "                           (delayed(pixelFeatures)(x[:, :, X_idx]) for X_idx in range(N)))\n",
    "    elif featureType == 'hog':\n",
    "        if dataType == 'digits-scaled.mat':\n",
    "            x = feature_normalization(x, 'L2-Norm')\n",
    "        features = np.empty((392, N)).astype('longdouble')\n",
    "        features = np.array(Parallel(n_jobs=multiprocessing.cpu_count()) \n",
    "                           (delayed(hogFeatures)(x[:, :, X_idx]) for X_idx in range(N)))\n",
    "    elif featureType == 'lbp':\n",
    "        features = np.empty((256, N)).astype('longdouble')\n",
    "        features = np.array(Parallel(n_jobs=multiprocessing.cpu_count()) \n",
    "                           (delayed(lbpFeatures)(x[:, :, X_idx]) for X_idx in range(N)))\n",
    "        \n",
    "    if featureType in ['lbp', 'pixel'] or dataType in ['digits-scaled.mat']:\n",
    "        features = feature_normalization(features, 'Sqrt')\n",
    "    return features.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    exp = np.exp(x - np.max(x))\n",
    "    return exp / np.array([np.sum(exp, axis=1)]).T\n",
    "\n",
    "def confusion_matrix(model, y):\n",
    "        confusion_matrix = np.zeros((model['numClass'], model['numClass']))\n",
    "        for itr in range(model['y_pred'].size):\n",
    "            confusion_matrix[y[itr], model['y_pred'][itr]] += 1\n",
    "        return confusion_matrix\n",
    "\n",
    "def accuracy(model, X, y):\n",
    "        y_pred = np.argmax(softmax(np.dot(X.T, model['w']) + model['b']), axis=1)\n",
    "        model['y_pred'] = y_pred\n",
    "        accuracy = np.sum([y_pred[i] == y[i] for i in range(y.size)]) / y.size\n",
    "        return model, accuracy\n",
    "\n",
    "def multiclassLRTrain(x, y, param):\n",
    "\n",
    "    classLabels = np.unique(y)\n",
    "    numClass = classLabels.shape[0]\n",
    "    numFeats = x.shape[0]\n",
    "    numData = x.shape[1]\n",
    "    \n",
    "\n",
    "    # Initialize weights randomly (Implement gradient descent)\n",
    "    model = {}\n",
    "    model['classLabels'] = classLabels\n",
    "    model['numClass'] = numClass\n",
    "    model['w'] = np.random.uniform(low=-0.01, high=.01, size=(x.shape[0], numClass))\n",
    "    model['b'] = np.random.uniform(low=-0.01, high=.01)\n",
    "    model['lastAccuracy'] = -1\n",
    "    model['debug'] = param['debug']\n",
    "    model['maxTol'] = param['maxTol']\n",
    "    y_categorical = np.eye(model['numClass'])[y] \n",
    "    curTol = 0\n",
    "        \n",
    "    for itr in range(param['maxiter']):\n",
    "        prediction = softmax(np.dot(x.T, model['w']))\n",
    "        error = y_categorical - prediction\n",
    "        gradient = np.dot(x, error)\n",
    "        model['w'] += param['eta'] * (gradient - (param['lambda'] * model['w']))\n",
    "        model['b'] -= param['eta'] * np.sum(error)\n",
    "\n",
    "        model, curr_accuracy = accuracy(model, param['x_val'], param['y_val'])\n",
    "        if curr_accuracy != model['lastAccuracy']:\n",
    "            model['lastAccuracy'] = curr_accuracy\n",
    "        else:\n",
    "            curTol += 1\n",
    "            if curTol >= model['maxTol']:\n",
    "                return model\n",
    "    return model\n",
    "\n",
    "def trainModel(x, y, x_val, y_val):\n",
    "    param = {}\n",
    "    param['lambda'] = 0.01      # Regularization term\n",
    "    param['maxiter'] = 20000     # Number of iterations\n",
    "    param['eta'] = 0.001         # Learning rate\n",
    "    param['x_val'] = x_val\n",
    "    param['y_val'] = y_val\n",
    "    param['debug'] = False\n",
    "    param['maxTol'] = 15\n",
    "    \n",
    "    return multiclassLRTrain(x, y, param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs682",
   "language": "python",
   "name": "cs682"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
