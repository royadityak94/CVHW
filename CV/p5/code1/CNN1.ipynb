{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "from utils import loadmat\n",
    "from extractDigitFeatures import extractDigitFeatures\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Conv3D, Flatten, MaxPool2D, AveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.python.keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.constraints import unit_norm\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_extractor(activation_func='relu', weight_decay=1e-4):\n",
    "    # Creating an AlexNet Classifier\n",
    "    model = Sequential()\n",
    "\n",
    "    #Instantiating Layer 1\n",
    "    model.add(Conv2D(48, kernel_size=(3, 3), strides=(1, 1), activation=activation_func, padding='valid', \n",
    "                    kernel_constraint=unit_norm(), kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # #Instantiating Layer 2\n",
    "    model.add(Conv2D(96, kernel_size=(3, 3), strides=(1, 1), activation=activation_func, padding='same', \n",
    "                    kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # #Instantiating Layer 3\n",
    "    model.add(Conv2D(192, kernel_size=(3, 3), strides=(1, 1), activation=activation_func, padding='same',\n",
    "                    kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # #Instantiating Layer 4\n",
    "    model.add(Conv2D(192, kernel_size=(3, 3), strides=(1, 1), activation=activation_func, padding='same', \n",
    "                    kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # #Instantiating Layer 5\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), strides=(1, 1), activation=activation_func, padding='same', \n",
    "                    kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Instantiating Layer 6\n",
    "    model.add(Dense(512, activation=activation_func)) \n",
    "\n",
    "    # #Instantiating Layer 8\n",
    "    model.add(Dense(256, activation=activation_func))\n",
    "\n",
    "    #Output Layer\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(x):\n",
    "    new_x = np.zeros((x.shape[2], x.shape[0], x.shape[1]))\n",
    "    for i in range(x.shape[2]):\n",
    "        new_x[i, :] = x[:, :, i]\n",
    "    return new_x[:, :, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_datasets(filename):\n",
    "    data = utils.loadmat('../data/{}'.format(filename))\n",
    "    trainSet, testSet, valSet = 1, 2, 3\n",
    "    \n",
    "    x_train = reformat(data['x'][:, :, data['set']==trainSet ])\n",
    "    y_train = (data['y'][data['set']==trainSet])\n",
    "    x_val = reformat(data['x'][:, :, data['set']==valSet])\n",
    "    y_val = (data['y'][data['set']==valSet])\n",
    "    x_test = reformat(data['x'][:, :, data['set']==testSet])\n",
    "    y_test = (data['y'][data['set']==testSet])\n",
    "    X = np.vstack([x_train, x_val])\n",
    "    Y = np.vstack([y_train[:, np.newaxis], y_val[:, np.newaxis]])\n",
    "    \n",
    "    return (X, Y, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1350 samples\n",
      "Epoch 1/15\n",
      "1350/1350 [==============================] - 3s 3ms/sample - loss: 129.8530 - accuracy: 0.0081\n",
      "Epoch 2/15\n",
      "1350/1350 [==============================] - 1s 931us/sample - loss: 265.8118 - accuracy: 0.0348\n",
      "Epoch 3/15\n",
      "1350/1350 [==============================] - 1s 843us/sample - loss: 701.6648 - accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "1350/1350 [==============================] - 1s 919us/sample - loss: 1562.2785 - accuracy: 7.4074e-04\n",
      "Epoch 5/15\n",
      "1350/1350 [==============================] - 1s 920us/sample - loss: 2966.2309 - accuracy: 0.0000e+00\n",
      "Epoch 6/15\n",
      "1350/1350 [==============================] - 1s 953us/sample - loss: 4948.9004 - accuracy: 0.0000e+00\n",
      "Epoch 7/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 7815.8483 - accuracy: 0.0000e+00\n",
      "Epoch 8/15\n",
      "1350/1350 [==============================] - 1s 980us/sample - loss: 11638.0887 - accuracy: 0.0000e+00\n",
      "Epoch 9/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 16481.3403 - accuracy: 0.0000e+00\n",
      "Epoch 10/15\n",
      "1350/1350 [==============================] - 1s 936us/sample - loss: 22679.6863 - accuracy: 0.0000e+00\n",
      "Epoch 11/15\n",
      "1350/1350 [==============================] - 1s 927us/sample - loss: 29707.3323 - accuracy: 0.0000e+00\n",
      "Epoch 12/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 38748.7564 - accuracy: 0.0000e+00\n",
      "Epoch 13/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 48966.4486 - accuracy: 0.0000e+00\n",
      "Epoch 14/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 60885.0855 - accuracy: 0.0000e+00\n",
      "Epoch 15/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 74234.6565 - accuracy: 0.0000e+00\n",
      "Accuracy = 0.0\n",
      "Train on 1350 samples\n",
      "Epoch 1/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 145.3812 - accuracy: 0.0022\n",
      "Epoch 2/15\n",
      "1350/1350 [==============================] - 1s 858us/sample - loss: 417.1132 - accuracy: 0.0000e+00\n",
      "Epoch 3/15\n",
      "1350/1350 [==============================] - 1s 897us/sample - loss: 1221.3763 - accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "1350/1350 [==============================] - 1s 911us/sample - loss: 2716.7208 - accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "1350/1350 [==============================] - 1s 789us/sample - loss: 5229.0659 - accuracy: 0.0000e+00\n",
      "Epoch 6/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 8899.1770 - accuracy: 0.0000e+00\n",
      "Epoch 7/15\n",
      "1350/1350 [==============================] - 1s 966us/sample - loss: 14069.7296 - accuracy: 0.0000e+00\n",
      "Epoch 8/15\n",
      "1350/1350 [==============================] - 1s 925us/sample - loss: 20613.1343 - accuracy: 0.0000e+00\n",
      "Epoch 9/15\n",
      "1350/1350 [==============================] - 1s 830us/sample - loss: 29432.0132 - accuracy: 0.0000e+00\n",
      "Epoch 10/15\n",
      "1350/1350 [==============================] - 1s 876us/sample - loss: 40351.5169 - accuracy: 0.0000e+00\n",
      "Epoch 11/15\n",
      "1350/1350 [==============================] - 1s 850us/sample - loss: 54034.1304 - accuracy: 0.0000e+00\n",
      "Epoch 12/15\n",
      "1350/1350 [==============================] - 1s 874us/sample - loss: 70595.6531 - accuracy: 0.0000e+00\n",
      "Epoch 13/15\n",
      "1350/1350 [==============================] - 1s 864us/sample - loss: 89270.2225 - accuracy: 0.0000e+00\n",
      "Epoch 14/15\n",
      "1350/1350 [==============================] - 1s 928us/sample - loss: 111557.5952 - accuracy: 0.0000e+00\n",
      "Epoch 15/15\n",
      "1350/1350 [==============================] - 1s 965us/sample - loss: 136968.6453 - accuracy: 0.0000e+00\n",
      "Accuracy = 0.0\n",
      "Train on 1350 samples\n",
      "Epoch 1/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 143.9976 - accuracy: 0.0348\n",
      "Epoch 2/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 351.2268 - accuracy: 0.0000e+00\n",
      "Epoch 3/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 899.2779 - accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "1350/1350 [==============================] - 1s 942us/sample - loss: 2013.7464 - accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 4024.7334 - accuracy: 0.0000e+00\n",
      "Epoch 6/15\n",
      "1350/1350 [==============================] - 1s 916us/sample - loss: 7066.9831 - accuracy: 0.0000e+00\n",
      "Epoch 7/15\n",
      "1350/1350 [==============================] - 1s 831us/sample - loss: 11387.4881 - accuracy: 0.0000e+00\n",
      "Epoch 8/15\n",
      "1350/1350 [==============================] - 1s 839us/sample - loss: 16934.5690 - accuracy: 0.0000e+00\n",
      "Epoch 9/15\n",
      "1350/1350 [==============================] - 1s 836us/sample - loss: 24461.8234 - accuracy: 0.0000e+00\n",
      "Epoch 10/15\n",
      "1350/1350 [==============================] - 1s 928us/sample - loss: 33237.6176 - accuracy: 0.0000e+00\n",
      "Epoch 11/15\n",
      "1350/1350 [==============================] - 1s 854us/sample - loss: 45118.6149 - accuracy: 0.0000e+00\n",
      "Epoch 12/15\n",
      "1350/1350 [==============================] - 1s 819us/sample - loss: 58801.4861 - accuracy: 0.0000e+00\n",
      "Epoch 13/15\n",
      "1350/1350 [==============================] - 1s 963us/sample - loss: 74914.9786 - accuracy: 0.0000e+00\n",
      "Epoch 14/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 93458.7870 - accuracy: 0.0000e+00\n",
      "Epoch 15/15\n",
      "1350/1350 [==============================] - 1s 880us/sample - loss: 116575.4789 - accuracy: 0.0000e+00\n",
      "Accuracy = 0.0\n",
      "Train on 1350 samples\n",
      "Epoch 1/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 133.3935 - accuracy: 0.0185\n",
      "Epoch 2/15\n",
      "1350/1350 [==============================] - 1s 923us/sample - loss: 322.0201 - accuracy: 0.0000e+00\n",
      "Epoch 3/15\n",
      "1350/1350 [==============================] - 1s 911us/sample - loss: 949.6398 - accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "1350/1350 [==============================] - 1s 885us/sample - loss: 2268.7777 - accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 4482.9909 - accuracy: 0.0000e+00\n",
      "Epoch 6/15\n",
      "1350/1350 [==============================] - 1s 992us/sample - loss: 7927.8141 - accuracy: 0.0000e+00\n",
      "Epoch 7/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 12879.2725 - accuracy: 0.0000e+00\n",
      "Epoch 8/15\n",
      "1350/1350 [==============================] - 1s 988us/sample - loss: 19355.3801 - accuracy: 0.0000e+00\n",
      "Epoch 9/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 27932.6881 - accuracy: 0.0000e+00\n",
      "Epoch 10/15\n",
      "1350/1350 [==============================] - 1s 973us/sample - loss: 38207.7354 - accuracy: 0.0000e+00\n",
      "Epoch 11/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 51252.9795 - accuracy: 0.0000e+00\n",
      "Epoch 12/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 66880.6319 - accuracy: 0.0000e+00\n",
      "Epoch 13/15\n",
      "1350/1350 [==============================] - 1s 985us/sample - loss: 85083.4829 - accuracy: 0.0000e+00\n",
      "Epoch 14/15\n",
      "1350/1350 [==============================] - 2s 1ms/sample - loss: 107314.9497 - accuracy: 0.0000e+00\n",
      "Epoch 15/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 130844.1545 - accuracy: 0.0000e+00\n",
      "Accuracy = 0.0\n",
      "Train on 1350 samples\n",
      "Epoch 1/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 164.3711 - accuracy: 0.0319\n",
      "Epoch 2/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 504.6351 - accuracy: 0.0000e+00\n",
      "Epoch 3/15\n",
      "1350/1350 [==============================] - 1s 969us/sample - loss: 1396.2965 - accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 3190.2285 - accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "1350/1350 [==============================] - 2s 1ms/sample - loss: 6030.2008 - accuracy: 0.0000e+00\n",
      "Epoch 6/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 10367.9187 - accuracy: 0.0000e+00\n",
      "Epoch 7/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 16292.0122 - accuracy: 0.0000e+00\n",
      "Epoch 8/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 23993.5243 - accuracy: 0.0000e+00\n",
      "Epoch 9/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 33840.7461 - accuracy: 0.0000e+00\n",
      "Epoch 10/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 45588.6014 - accuracy: 0.0000e+00\n",
      "Epoch 11/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 60329.8971 - accuracy: 0.0000e+00\n",
      "Epoch 12/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350/1350 [==============================] - 2s 1ms/sample - loss: 78643.8990 - accuracy: 0.0000e+00\n",
      "Epoch 13/15\n",
      "1350/1350 [==============================] - 1s 1ms/sample - loss: 99163.3993 - accuracy: 0.0000e+00\n",
      "Epoch 14/15\n",
      "1350/1350 [==============================] - 2s 1ms/sample - loss: 122647.1574 - accuracy: 0.0000e+00\n",
      "Epoch 15/15\n",
      "1350/1350 [==============================] - 2s 1ms/sample - loss: 150605.2587 - accuracy: 0.0000e+00\n",
      "Accuracy = 0.0\n",
      "Train on 1350 samples\n",
      "Epoch 1/15\n",
      "1350/1350 [==============================] - 6s 4ms/sample - loss: 134.5328 - accuracy: 0.3844\n",
      "Epoch 2/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 290.5045 - accuracy: 0.1437\n",
      "Epoch 3/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 761.0211 - accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 1795.8707 - accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 3679.2860 - accuracy: 0.0000e+00\n",
      "Epoch 6/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 6614.5008 - accuracy: 0.0000e+00\n",
      "Epoch 7/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 10696.6599 - accuracy: 0.0000e+00\n",
      "Epoch 8/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 16438.2530 - accuracy: 0.0000e+00\n",
      "Epoch 9/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 23878.1121 - accuracy: 0.0000e+00\n",
      "Epoch 10/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 33574.1263 - accuracy: 0.0000e+00\n",
      "Epoch 11/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 45196.1714 - accuracy: 0.0000e+00\n",
      "Epoch 12/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 59423.4614 - accuracy: 0.0000e+00\n",
      "Epoch 13/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 76444.7309 - accuracy: 0.0000e+00\n",
      "Epoch 14/15\n",
      "1350/1350 [==============================] - 2s 1ms/sample - loss: 96783.2335 - accuracy: 0.0000e+00\n",
      "Epoch 15/15\n",
      "1350/1350 [==============================] - 2s 1ms/sample - loss: 120144.3472 - accuracy: 0.0000e+00\n",
      "Accuracy = 0.0\n",
      "Train on 1350 samples\n",
      "Epoch 1/15\n",
      "1350/1350 [==============================] - 7s 5ms/sample - loss: 159.0463 - accuracy: 0.0000e+00\n",
      "Epoch 2/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 601.8292 - accuracy: 0.0000e+00\n",
      "Epoch 3/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 1914.4415 - accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 4563.5492 - accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 8903.8865 - accuracy: 0.0000e+00\n",
      "Epoch 6/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 15497.9800 - accuracy: 0.0000e+00\n",
      "Epoch 7/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 25070.2784 - accuracy: 0.0000e+00\n",
      "Epoch 8/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 37640.9540 - accuracy: 0.0000e+00\n",
      "Epoch 9/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 53865.3961 - accuracy: 0.0000e+00\n",
      "Epoch 10/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 74657.1528 - accuracy: 0.0000e+00\n",
      "Epoch 11/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 99868.4852 - accuracy: 0.0000e+00\n",
      "Epoch 12/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 130134.5770 - accuracy: 0.0000e+00\n",
      "Epoch 13/15\n",
      "1350/1350 [==============================] - 2s 2ms/sample - loss: 167007.7257 - accuracy: 0.0000e+00\n",
      "Epoch 14/15\n",
      "1350/1350 [==============================] - 2s 1ms/sample - loss: 206644.4641 - accuracy: 0.0000e+00\n",
      "Epoch 15/15\n",
      "1350/1350 [==============================] - 2s 1ms/sample - loss: 251372.5278 - accuracy: 0.0000e+00\n",
      "Accuracy = 0.0\n",
      "Train on 1350 samples\n",
      "Epoch 1/15\n",
      "1350/1350 [==============================] - 7s 5ms/sample - loss: 133.5665 - accuracy: 0.0274\n",
      "Epoch 2/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 328.9953 - accuracy: 0.0000e+00\n",
      "Epoch 3/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 885.5004 - accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "1350/1350 [==============================] - 3s 3ms/sample - loss: 2028.2017 - accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 3922.7073 - accuracy: 0.0000e+00\n",
      "Epoch 6/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 6779.9191 - accuracy: 0.0000e+00\n",
      "Epoch 7/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 10695.2150 - accuracy: 0.0000e+00\n",
      "Epoch 8/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 15860.6814 - accuracy: 0.0000e+00\n",
      "Epoch 9/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 22268.3900 - accuracy: 0.0000e+00\n",
      "Epoch 10/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 30642.2765 - accuracy: 0.0000e+00\n",
      "Epoch 11/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 40624.6325 - accuracy: 0.0000e+00\n",
      "Epoch 12/15\n",
      "1350/1350 [==============================] - 2s 2ms/sample - loss: 51965.4570 - accuracy: 0.0000e+00\n",
      "Epoch 13/15\n",
      "1350/1350 [==============================] - 2s 1ms/sample - loss: 66110.9896 - accuracy: 0.0000e+00\n",
      "Epoch 14/15\n",
      "1350/1350 [==============================] - 2s 1ms/sample - loss: 82487.7734 - accuracy: 0.0000e+00\n",
      "Epoch 15/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 101699.1826 - accuracy: 0.0000e+00\n",
      "Accuracy = 0.0\n",
      "Train on 1350 samples\n",
      "Epoch 1/15\n",
      "1350/1350 [==============================] - 7s 5ms/sample - loss: 137.8572 - accuracy: 0.0178\n",
      "Epoch 2/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 368.3705 - accuracy: 0.0000e+00\n",
      "Epoch 3/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 1059.8884 - accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 2395.5750 - accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 4671.9920 - accuracy: 0.0000e+00\n",
      "Epoch 6/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 7894.6994 - accuracy: 0.0000e+00\n",
      "Epoch 7/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 12600.1618 - accuracy: 0.0000e+00\n",
      "Epoch 8/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 18886.2504 - accuracy: 0.0000e+00\n",
      "Epoch 9/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 26793.0866 - accuracy: 0.0000e+00\n",
      "Epoch 10/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 37224.6957 - accuracy: 0.0000e+00\n",
      "Epoch 11/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 49681.5129 - accuracy: 0.0000e+00\n",
      "Epoch 12/15\n",
      "1350/1350 [==============================] - 2s 2ms/sample - loss: 64475.4867 - accuracy: 0.0000e+00\n",
      "Epoch 13/15\n",
      "1350/1350 [==============================] - 2s 1ms/sample - loss: 80770.0917 - accuracy: 0.0000e+00\n",
      "Epoch 14/15\n",
      "1350/1350 [==============================] - 2s 1ms/sample - loss: 101254.6554 - accuracy: 0.0000e+00\n",
      "Epoch 15/15\n",
      "1350/1350 [==============================] - 2s 2ms/sample - loss: 123725.3015 - accuracy: 0.0000e+00\n",
      "Accuracy = 0.0\n",
      "Train on 1350 samples\n",
      "Epoch 1/15\n",
      "1350/1350 [==============================] - 7s 5ms/sample - loss: 140.9911 - accuracy: 0.7311\n",
      "Epoch 2/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 436.2512 - accuracy: 1.0000\n",
      "Epoch 3/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 1407.5270 - accuracy: 1.0000\n",
      "Epoch 4/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 3399.8825 - accuracy: 1.0000\n",
      "Epoch 5/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 6614.4663 - accuracy: 1.0000\n",
      "Epoch 6/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 11253.1753 - accuracy: 1.0000\n",
      "Epoch 7/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 17907.7044 - accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 26990.1104 - accuracy: 1.0000\n",
      "Epoch 9/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 38274.9076 - accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 52844.1615 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "1350/1350 [==============================] - 3s 2ms/sample - loss: 70777.9196 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "1350/1350 [==============================] - 2s 2ms/sample - loss: 91467.6262 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "1350/1350 [==============================] - 2s 2ms/sample - loss: 114866.6808 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "1350/1350 [==============================] - 2s 2ms/sample - loss: 142715.0590 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "1350/1350 [==============================] - 5s 3ms/sample - loss: 174654.8351 - accuracy: 1.0000\n",
      "Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "X, Y, x_test, y_test = return_datasets('digits-scaled.mat')\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "for train, test in kfold.split(X, Y):\n",
    "    model = model_extractor('relu')\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='Adam', metrics=[\"accuracy\"])\n",
    "    model.fit(X[train], Y[train], epochs=15, batch_size=200, verbose=1)\n",
    "    accuracy = model.evaluate(X[test], Y[test], batch_size=int(Y[test].size/5), verbose=0)[1]\n",
    "    print (\"Accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy for = [151562.81018830778, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print (\"Test Set Accuracy for = {}\".format(model.evaluate(x_test, y_test, verbose=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Test Set Accuracy for = {}\".format(best_model.evaluate(x_test, y_test, verbose=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8ddd28cb70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[1].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, x_test, y_test = return_datasets(file)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "best_model, best_accuracy = -1, 0\n",
    "for train, test in kfold.split(X, Y):\n",
    "    model = model_extractor('selu')\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='Adam', metrics=[\"accuracy\"])\n",
    "    model.fit(X[train], Y[train], epochs=15, batch_size=200, verbose=0)\n",
    "    scores = model.evaluate(X[test], Y[test], batch_size=int(Y[test].size/5), verbose=0)\n",
    "    print (\"Accuracy = {}\".format(scores[1]))\n",
    "    if scores[1] > best_accuracy:\n",
    "        best_accuracy = scores[1]\n",
    "        best_model = model\n",
    "\n",
    "    if best_accuracy > .99:\n",
    "        break    \n",
    "\n",
    "print (\"Test Set Accuracy for {} = {}\".format(file, best_model.evaluate(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs682",
   "language": "python",
   "name": "cs682"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
